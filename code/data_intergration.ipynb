{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tom1/Documents/GitHub/Blockhouse-Work-Trial/code\n",
      "['data_intergration.ipynb', 'TomiCode.py', 'Readme.md', 'benchmark_costs_script.py']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Print the current working directory\n",
    "print(os.getcwd())\n",
    "# List all files in the current directory\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after loading data: Index(['timestamp', 'bid_price_1', 'bid_price_2', 'bid_price_3', 'bid_price_4',\n",
      "       'bid_price_5', 'bid_size_1', 'bid_size_2', 'bid_size_3', 'bid_size_4',\n",
      "       'bid_size_5', 'ask_price_1', 'ask_price_2', 'ask_price_3',\n",
      "       'ask_price_4', 'ask_price_5', 'ask_size_1', 'ask_size_2', 'ask_size_3',\n",
      "       'ask_size_4', 'ask_size_5'],\n",
      "      dtype='object')\n",
      "Columns after renaming: Index(['timestamp', 'bid_price_1', 'bid_price_2', 'bid_price_3', 'bid_price_4',\n",
      "       'bid_price_5', 'bid_size_1', 'bid_size_2', 'bid_size_3', 'bid_size_4',\n",
      "       'bid_size_5', 'ask_price_1', 'ask_price_2', 'ask_price_3',\n",
      "       'ask_price_4', 'ask_price_5', 'ask_size_1', 'ask_size_2', 'ask_size_3',\n",
      "       'ask_size_4', 'ask_size_5'],\n",
      "      dtype='object')\n",
      "Columns after adding placeholders: Index(['timestamp', 'bid_price_1', 'bid_price_2', 'bid_price_3', 'bid_price_4',\n",
      "       'bid_price_5', 'bid_size_1', 'bid_size_2', 'bid_size_3', 'bid_size_4',\n",
      "       'bid_size_5', 'ask_price_1', 'ask_price_2', 'ask_price_3',\n",
      "       'ask_price_4', 'ask_price_5', 'ask_size_1', 'ask_size_2', 'ask_size_3',\n",
      "       'ask_size_4', 'ask_size_5'],\n",
      "      dtype='object')\n",
      "Error with columns: \"['close', 'volume'] not in index\"\n",
      "Available columns at scaling: Index(['timestamp', 'bid_price_1', 'bid_price_2', 'bid_price_3', 'bid_price_4',\n",
      "       'bid_price_5', 'bid_size_1', 'bid_size_2', 'bid_size_3', 'bid_size_4',\n",
      "       'bid_size_5', 'ask_price_1', 'ask_price_2', 'ask_price_3',\n",
      "       'ask_price_4', 'ask_price_5', 'ask_size_1', 'ask_size_2', 'ask_size_3',\n",
      "       'ask_size_4', 'ask_size_5'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load market data\n",
    "file_path = '../data/AAPL_Quotes_Data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Verify the columns in the loaded DataFrame\n",
    "print(\"Columns after loading data:\", data.columns)\n",
    "\n",
    "# Verify and rename columns to match expected names\n",
    "expected_columns = {'Close': 'close', 'Volume': 'volume', 'Ask_price_1': 'ask_price_1', 'Bid_price_1': 'bid_price_1'}\n",
    "for col, new_col in expected_columns.items():\n",
    "    if col in data.columns:\n",
    "        data.rename(columns={col: new_col}, inplace=True)\n",
    "\n",
    "# Print columns after renaming\n",
    "print(\"Columns after renaming:\", data.columns)\n",
    "\n",
    "# Add placeholder columns for ask_price_1 and bid_price_1 if necessary\n",
    "if 'ask_price_1' not in data.columns:\n",
    "    data['ask_price_1'] = np.nan  # or 0\n",
    "if 'bid_price_1' not in data.columns:\n",
    "    data['bid_price_1'] = np.nan  # or 0\n",
    "\n",
    "# Print columns after adding placeholder columns\n",
    "print(\"Columns after adding placeholders:\", data.columns)\n",
    "\n",
    "# Normalize the necessary columns\n",
    "scaler = MinMaxScaler()\n",
    "try:\n",
    "    data[['close', 'ask_price_1', 'bid_price_1', 'volume']] = scaler.fit_transform(data[['close', 'ask_price_1', 'bid_price_1', 'volume']])\n",
    "except KeyError as e:\n",
    "    print(\"Error with columns:\", e)\n",
    "    print(\"Available columns at scaling:\", data.columns)\n",
    "\n",
    "# Ensure data is sorted by 'Date'\n",
    "# if 'Date' in data.columns:\n",
    "#     data.sort_values(by='Date', inplace=True)\n",
    "#     data.reset_index(drop=True, inplace=True)\n",
    "# else:\n",
    "#     raise KeyError(\"'Date' column not found to sort the DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "class CustomTradingEnv(gym.Env):\n",
    "    def __init__(self, data, initial_inventory=1000):\n",
    "        super(CustomTradingEnv, self).__init__()\n",
    "        self.data = data\n",
    "        self.inventory = initial_inventory\n",
    "        self.current_step = 0\n",
    "        self.action_space = spaces.Discrete(3)  # Actions: sell_some, sell_more, do_nothing\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(data.shape[1],), dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.inventory = 1000\n",
    "        return self.data.iloc[self.current_step].values\n",
    "\n",
    "    def step(self, action):\n",
    "        current_state = self.data.iloc[self.current_step].values\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.data) - 1 or self.inventory <= 0\n",
    "\n",
    "        # Define how much to sell based on action\n",
    "        if action == 0:  # sell_some\n",
    "            traded_shares = min(10, self.inventory)\n",
    "        elif action == 1:  # sell_more\n",
    "            traded_shares = min(20, self.inventory)\n",
    "        else:  # do_nothing\n",
    "            traded_shares = 0\n",
    "\n",
    "        # Simulate the trade execution\n",
    "        execution_price = self.data.iloc[self.current_step]['close']\n",
    "        reward = - (execution_price * traded_shares)  # Negative because we want to minimize cost\n",
    "        self.inventory -= traded_shares\n",
    "\n",
    "        next_state = self.data.iloc[self.current_step].values\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "data = pd.read_csv('../data/AAPL_Quotes_Data.csv')\n",
    "env = CustomTradingEnv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "\n",
    "class CustomTradingEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Custom Trading Environment that follows Gymnasium interface.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        super(CustomTradingEnv, self).__init__()\n",
    "        self.data = data\n",
    "        self.current_step = 0\n",
    "        \n",
    "        # Define action and observation space\n",
    "        self.action_space = spaces.Discrete(3)  # Example: Buy, Hold, Sell\n",
    "        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(data.shape[1],), dtype=np.float32)  # Adjust based on observation structure\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset the environment to the initial state and return the initial observation.\n",
    "        \"\"\"\n",
    "        self.current_step = 0\n",
    "        return self._next_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Execute one time step within the environment.\n",
    "\n",
    "        Args:\n",
    "            action (int): The action taken by the agent.\n",
    "\n",
    "        Returns:\n",
    "            observation (array): Next observation.\n",
    "            reward (float): Rewardearned for the action.\n",
    "            done (bool): Whether the episode has ended.\n",
    "            info (dict): Additional information.\n",
    "        \"\"\"\n",
    "        self.current_step += 1\n",
    "        reward = 0  # Define the reward logic here\n",
    "        done = self.current_step >= len(self.data)\n",
    "        return self._next_observation(), reward, done, {}\n",
    "\n",
    "    def _next_observation(self):\n",
    "        \"\"\"\n",
    "        Get the next observation.\n",
    "        \"\"\"\n",
    "        return self.data[self.current_step]\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        \"\"\"\n",
    "        Render the environment.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Clean up resources.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Your environment must inherit from the gymnasium.Env class cf. https://gymnasium.farama.org/api/env/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/tom1/Documents/GitHub/Blockhouse-Work-Trial/code/data_intergration.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tom1/Documents/GitHub/Blockhouse-Work-Trial/code/data_intergration.ipynb#W3sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# Verify the custom environment\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tom1/Documents/GitHub/Blockhouse-Work-Trial/code/data_intergration.ipynb#W3sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m env \u001b[39m=\u001b[39m CustomTradingEnv(data)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tom1/Documents/GitHub/Blockhouse-Work-Trial/code/data_intergration.ipynb#W3sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m check_env(env)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tom1/Documents/GitHub/Blockhouse-Work-Trial/code/data_intergration.ipynb#W3sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m# Define and train the SAC model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tom1/Documents/GitHub/Blockhouse-Work-Trial/code/data_intergration.ipynb#W3sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m model \u001b[39m=\u001b[39m SAC(\u001b[39m'\u001b[39m\u001b[39mMlpPolicy\u001b[39m\u001b[39m'\u001b[39m, env, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/Blockhouse-Work-Trial/tradingcode/lib/python3.12/site-packages/stable_baselines3/common/env_checker.py:421\u001b[0m, in \u001b[0;36mcheck_env\u001b[0;34m(env, warn, skip_render_check)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_env\u001b[39m(env: gym\u001b[39m.\u001b[39mEnv, warn: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, skip_render_check: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[39m    Check that an environment follows Gym API.\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[39m    This is particularly useful when using a custom environment.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[39m        True by default (useful for the CI)\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    422\u001b[0m         env, gym\u001b[39m.\u001b[39mEnv\n\u001b[1;32m    423\u001b[0m     ), \u001b[39m\"\u001b[39m\u001b[39mYour environment must inherit from the gymnasium.Env class cf. https://gymnasium.farama.org/api/env/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    425\u001b[0m     \u001b[39m# ============= Check the spaces (observation and action) ================\u001b[39;00m\n\u001b[1;32m    426\u001b[0m     _check_spaces(env)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Your environment must inherit from the gymnasium.Env class cf. https://gymnasium.farama.org/api/env/"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import gym\n",
    "\n",
    "# Example data creation for demonstration purposes\n",
    "data = pd.DataFrame({\n",
    "    'close': np.random.rand(100),  # This should be actual market data 'close' prices\n",
    "    'volume': np.random.randint(1, 100, 100)  # This should be actual market data 'volume'\n",
    "})\n",
    "\n",
    "def twap_strategy(initial_inventory, num_steps):\n",
    "    return [(initial_inventory // num_steps) for _ in range(num_steps)]\n",
    "\n",
    "def vwap_strategy(data, initial_inventory):\n",
    "    total_volume = data['volume'].sum()\n",
    "    return [(initial_inventory * (volume / total_volume)) for volume in data['volume']]\n",
    "\n",
    "def backtest_strategy(strategy, data, initial_inventory):\n",
    "    total_cost = 0\n",
    "    inventory = initial_inventory\n",
    "    for step, shares_to_trade in enumerate(strategy):\n",
    "        execution_price = data.iloc[step]['close']\n",
    "        total_cost += execution_price * shares_to_trade\n",
    "        inventory -= shares_to_trade\n",
    "    return total_cost\n",
    "\n",
    "# Check if 'close' column exists\n",
    "assert 'close' in data.columns, \"'close' column is missing from data\"\n",
    "\n",
    "# Backtest TWAP\n",
    "twap_trades = twap_strategy(1000, len(data))\n",
    "twap_cost = backtest_strategy(twap_trades, data, 1000)\n",
    "\n",
    "# Backtest VWAP\n",
    "vwap_trades = vwap_strategy(data, 1000)\n",
    "vwap_cost = backtest_strategy(vwap_trades, data, 1000)\n",
    "\n",
    "# Define the custom environment for SAC\n",
    "class CustomTradingEnv(gym.Env):\n",
    "    def __init__(self, data):\n",
    "        super(CustomTradingEnv, self).__init__()\n",
    "        self.data = data\n",
    "        self.action_space = gym.spaces.Discrete(len(data))\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(len(data.columns),), dtype=np.float32)\n",
    "        self.current_step = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        return self.data.iloc[self.current_step].values\n",
    "\n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.data) - 1\n",
    "        obs = self.data.iloc[self.current_step].values if not done else None\n",
    "        reward = -abs(action - self.data['close'].iloc[self.current_step])  \n",
    "        return obs, reward, done, {}\n",
    "\n",
    "# Verify the custom environment\n",
    "env = CustomTradingEnv(data)\n",
    "check_env(env)\n",
    "\n",
    "# Define and train the SAC model\n",
    "model = SAC('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# Optional: Save the trained model\n",
    "model.save(\"sac_trading_model\")\n",
    "\n",
    "# Backtest the SAC model\n",
    "obs = env.reset()\n",
    "done = False\n",
    "sac_total_cost = 0\n",
    "while not done:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    sac_total_cost += rewards\n",
    "\n",
    "print(f\"TWAP Cost: {twap_cost}\")\n",
    "print(f\"VWAP Cost: {vwap_cost}\")\n",
    "print(f\"SAC Model Cost: {sac_total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/tom1/Documents/GitHub/Blockhouse-Work-Trial/code/data_intergration.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tom1/Documents/GitHub/Blockhouse-Work-Trial/code/data_intergration.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m obs \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()  \u001b[39m# Reset the environment to the initial state\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tom1/Documents/GitHub/Blockhouse-Work-Trial/code/data_intergration.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(data)):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tom1/Documents/GitHub/Blockhouse-Work-Trial/code/data_intergration.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     action, _states \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(obs, deterministic\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \u001b[39m# Predict action based on current observation\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tom1/Documents/GitHub/Blockhouse-Work-Trial/code/data_intergration.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     obs, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)  \u001b[39m# Execute action in the environment\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tom1/Documents/GitHub/Blockhouse-Work-Trial/code/data_intergration.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mif\u001b[39;00m done:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "obs = env.reset()  # Reset the environment to the initial state\n",
    "for _ in range(len(data)):\n",
    "    action, _states = model.predict(obs, deterministic=True)  # Predict action based on current observation\n",
    "    obs, reward, done, info = env.step(action)  # Execute action in the environment\n",
    "    if done:\n",
    "        break  # Break if the episode is done\n",
    "\n",
    "# Print final results\n",
    "print(f\"Final inventory: {env.inventory}\")\n",
    "print(f\"Final cash: {env.cash}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tradingcode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
